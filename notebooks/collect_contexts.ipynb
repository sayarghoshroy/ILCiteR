{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Rcq495_ar9-9WrUCY6sI2U9hjwbikmTn",
      "authorship_tag": "ABX9TyMtrBi2BeiyeevBwDubcMNA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anon/ILCiteR/blob/main/collect_contexts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vOZtMkfqcKyO"
      },
      "outputs": [],
      "source": [
        "# Step 1: Group all contexts from\n",
        "# (a) The test set\n",
        "# (b) The fetched candidate contexts corresponding to each test datapoint\n",
        "\n",
        "# Store them in an indexed list and a set\n",
        "# Fetch their Embeddings using SciBERT\n",
        "# Create a dictionary mapping each text contect to SciBERT embedding\n",
        "\n",
        "# Consider all 4 domains together"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "YrrDBPbFdNfc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location = 'drive/My Drive/cite_reco_s2orc/full/'\n",
        "expts_loc = 'experiments/'\n",
        "prefetch_loc = expts_loc + 'prefetch/'\n",
        "maps_loc = 'maps/'\n",
        "map_types = ['Test/', 'Database/']\n",
        "\n",
        "domains = ['ner', 'sa', 'summ', 'mt']\n",
        "algos = ['BM25Okapi', 'BM25Plus']\n",
        "test_count = 500"
      ],
      "metadata": {
        "id": "drrq8QUMdhEM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_database(domain):\n",
        "  global location, maps_loc, map_types\n",
        "\n",
        "  with open(location + maps_loc + map_types[1] + domain + '.json', 'r+') as f:\n",
        "    database = json.load(f)\n",
        "\n",
        "  return database\n",
        "\n",
        "def get_test_set(domain):\n",
        "  global location, maps_loc, map_types, test_count\n",
        "\n",
        "  with open(location + maps_loc + map_types[0] + domain + '_' + str(test_count) + '.json', 'r+') as f:\n",
        "    test_set = json.load(f)\n",
        "\n",
        "  return test_set\n",
        "\n",
        "def dump_all_contexts(all_contexts):\n",
        "  global location, expts_loc, test_count\n",
        "\n",
        "  with open(location + expts_loc + 'all_contexts_' + str(test_count) + '.json', 'w+') as f:\n",
        "    json.dump(all_contexts, f)\n",
        "\n",
        "  return\n",
        "\n",
        "def load_prefetch(domain, algo):\n",
        "  global location, prefetch_loc, test_count\n",
        "\n",
        "  with open(location + prefetch_loc + domain + '_' + str(test_count) + '_' + algo + '.json', 'r+') as f:\n",
        "    prefetched = json.load(f)\n",
        "\n",
        "  return prefetched\n",
        "\n",
        "def get_contexts(prefetched, database_contexts, test_set_contexts):\n",
        "  contexts_set = set()\n",
        "\n",
        "  for test_index, prefetched_candidate_scores in enumerate(prefetched):\n",
        "    database_candidate_indices = [unit[1] for unit in prefetched_candidate_scores]\n",
        "\n",
        "    contexts_set.add(test_set_contexts[test_index])\n",
        "\n",
        "    for database_index in database_candidate_indices:\n",
        "      contexts_set.add(database_contexts[database_index])\n",
        "\n",
        "  return contexts_set"
      ],
      "metadata": {
        "id": "MfC_-bVueKQt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Test on a single domain\n",
        "\n",
        "run_unit_test = False\n",
        "\n",
        "if run_unit_test:\n",
        "  database = get_database('ner')\n",
        "  database_contexts = [context for context in database.keys()]\n",
        "  test_set = get_test_set('ner')\n",
        "  test_set_contexts = [datapoint[0] for datapoint in test_set]\n",
        "  prefetched = load_prefetch('ner', 'BM25Plus')\n",
        "  contexts_set = get_contexts(prefetched, database_contexts, test_set_contexts)\n",
        "  dump_all_contexts(list(contexts_set))"
      ],
      "metadata": {
        "id": "pGHzXsv-ek3D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Considering all domains and algorithms\n",
        "\n",
        "all_contexts = set()\n",
        "\n",
        "for domain in tqdm.tqdm(domains):\n",
        "  database = get_database(domain)\n",
        "  database_contexts = [context for context in database.keys()]\n",
        "  test_set = get_test_set(domain)\n",
        "  test_set_contexts = [datapoint[0] for datapoint in test_set]\n",
        "\n",
        "  for algo in algos:\n",
        "    prefetched = load_prefetch(domain, algo)\n",
        "    contexts_set = get_contexts(prefetched, database_contexts, test_set_contexts)\n",
        "\n",
        "    all_contexts = all_contexts.union(contexts_set)\n",
        "\n",
        "all_contexts = list(all_contexts)\n",
        "dump_all_contexts(all_contexts)\n",
        "\n",
        "tqdm.tqdm.write('')\n",
        "\n",
        "print('Number of contexts fetched: ' + str(len(all_contexts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfPfuqdfe6H5",
        "outputId": "6c2a3dcb-df68-4122-e9eb-bc6b05936304"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:12<00:00,  3.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of contexts fetched: 64765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# That's it"
      ],
      "metadata": {
        "id": "gP57sXLOe9eW"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}