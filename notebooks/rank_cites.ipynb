{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qIE8NWeTbBQHOhPVFsMPvuXCJYeL4uX8",
      "authorship_tag": "ABX9TyOnOJCOShK94cdWyQH7rAXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anon/ILCiteR/blob/main/rank_cites.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "53JzaHM3m5h4"
      },
      "outputs": [],
      "source": [
        "# Step 1: Given a test case, Pre-fetch and Rank candidate citation contexts\n",
        "# Step 2: Rank corresponding set of research articles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import numpy\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "rKc6Efa50OYm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_location = 'drive/My Drive/cite_reco_s2orc/full/'\n",
        "test_size = '500'\n",
        "prefetched_size = 50\n",
        "\n",
        "test_map_loc = 'maps/Test/'\n",
        "db_map_loc = 'maps/Database/'\n",
        "expts_loc = 'experiments/'\n",
        "prefetched_loc = expts_loc + 'prefetch/'"
      ],
      "metadata": {
        "id": "8Vg84MIQyAyI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment Parameters\n",
        "\n",
        "domains = ['ner', 'summ', 'mt']\n",
        "indices_possibilities = [[2], [0, 2], [1, 2], [0, 1, 2], [0], [1], [0, 1]]\n",
        "mode = 1 # 0 for normal mode, 1 for hybrid mode\n",
        "switch_threshold = 50 # Only used if mode == 1"
      ],
      "metadata": {
        "id": "SP8YSMjdeaCB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(base_location + expts_loc + 'context_to_embed_' + test_size + '.pkl', 'rb') as f:\n",
        "  context_to_emded = pickle.load(f)\n",
        "\n",
        "with open(base_location + expts_loc + 'all_contexts_' + test_size + '.json', 'r+') as f:\n",
        "  all_contexts = json.load(f)"
      ],
      "metadata": {
        "id": "4OQAnZcozKMJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_files(domain):\n",
        "  global base_location, test_size, test_map_loc, db_map_loc, prefetched_loc\n",
        "\n",
        "  with open(base_location + test_map_loc + domain + '_' + test_size + '.json', 'r+') as f:\n",
        "    test_set = json.load(f)\n",
        "\n",
        "  with open(base_location + db_map_loc + domain + '.json', 'r+') as f:\n",
        "    database_dict = json.load(f)\n",
        "\n",
        "  database = [[context, database_dict[context]] for context in database_dict.keys()]\n",
        "\n",
        "  with open(base_location + prefetched_loc + domain + '_' + test_size + '_BM25Okapi.json', 'r+') as f:\n",
        "    BM25Okapi_fetched = json.load(f)\n",
        "\n",
        "  with open(base_location + prefetched_loc + domain + '_' + test_size + '_BM25Plus.json', 'r+') as f:\n",
        "    BM25Plus_fetched = json.load(f)\n",
        "\n",
        "  return test_set, database, BM25Okapi_fetched, BM25Plus_fetched"
      ],
      "metadata": {
        "id": "08VKBtRYzUQh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit Test\n",
        "\n",
        "run_unit_test = True\n",
        "if run_unit_test:\n",
        "  domain = 'ner'\n",
        "  indices = [0, 1, 2]\n",
        "  test_set, database, BM25Okapi_fetched, BM25Plus_fetched = load_files(domain)"
      ],
      "metadata": {
        "id": "o6XRi-2h0lyM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(x, y):\n",
        "  sim_type = 0\n",
        "  if sim_type == 0:\n",
        "    # Cosine Similarity\n",
        "    return numpy.dot(x, y) / (numpy.linalg.norm(x) * numpy.linalg.norm(y))\n",
        "  elif sim_type == 1:\n",
        "    # Distance\n",
        "    return - numpy.linalg.norm(x - y)\n",
        "  elif sim_type == 2:\n",
        "    # Dot Product\n",
        "    return numpy.dot(x, y)\n",
        "\n",
        "def get_SciBERT_scores(candidate_IDs, test_context):\n",
        "  global database, context_to_emded\n",
        "  test_embed = context_to_emded[test_context]\n",
        "  score_candidate_ID = []\n",
        "\n",
        "  for ID in candidate_IDs:\n",
        "    candidate_text = database[ID][0]\n",
        "    candidate_embed = context_to_emded[candidate_text]\n",
        "    score = similarity(candidate_embed, test_embed)\n",
        "    score_candidate_ID.append([score, ID])\n",
        "\n",
        "  score_candidate_ID = sorted(score_candidate_ID, reverse = True)\n",
        "  return score_candidate_ID\n",
        "\n",
        "def combine_ranks(list_of_ranks, test_point):\n",
        "  # indices stores the indicies to be considered: [0, 1, 2] for all three rankings\n",
        "  global indices, mode, switch_threshold\n",
        "  if mode == 0:\n",
        "    total = sum([list_of_ranks[index] for index in indices])\n",
        "  else:\n",
        "    if test_point[0].count(' ') > switch_threshold:\n",
        "      total = list_of_ranks[1] + list_of_ranks[2]\n",
        "    else:\n",
        "      total = list_of_ranks[0] + list_of_ranks[1]\n",
        "  return total\n",
        "\n",
        "def is_same_paper(paper_A, paper_B):\n",
        "  if paper_A['title'].lower().strip() == paper_B['title'].lower().strip() and paper_A['year'] == paper_B['year']:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def search_paper(query_paper, ranked_paper_order):\n",
        "  for index, paper in enumerate(ranked_paper_order):\n",
        "    if is_same_paper(query_paper, paper):\n",
        "      return index\n",
        "\n",
        "  return -1\n",
        "\n",
        "def Reci_Rank(ranked_paper_order, ground_truth_papers):\n",
        "  reci_ranks = [0]\n",
        "  for actual in ground_truth_papers:\n",
        "    found_at = search_paper(actual, ranked_paper_order)\n",
        "    if found_at == -1:\n",
        "        continue\n",
        "    reci_ranks.append(1 / (found_at + 1))\n",
        "  return max(reci_ranks)\n",
        "\n",
        "def Rec_at_K(ranked_paper_order, ground_truth_papers, K = 10):\n",
        "  l = len(ranked_paper_order)\n",
        "  for actual in ground_truth_papers:\n",
        "    found_at = search_paper(actual, ranked_paper_order[0 : min(K, l)])\n",
        "    if found_at != -1:\n",
        "        return 1\n",
        "  return 0\n",
        "\n",
        "def rank_candidate_contexts(test_point, p_okapi, p_plus):\n",
        "  global prefetched_size\n",
        "  test_context = test_point[0]\n",
        "  true_papers = test_point[1]\n",
        "\n",
        "  candidate_ID_to_ranks = {}\n",
        "  # Maps candidate ID to 3 ranks: based on BM25Okapi, BM25Plus, and SciBERT similarity\n",
        "\n",
        "  for index, [score, ID] in enumerate(p_okapi):\n",
        "    candidate_ID_to_ranks[ID] = [index, prefetched_size, prefetched_size]\n",
        "\n",
        "  for index, [score, ID] in enumerate(p_plus):\n",
        "    if ID not in candidate_ID_to_ranks:\n",
        "      candidate_ID_to_ranks[ID] = [prefetched_size, index, prefetched_size]\n",
        "    else:\n",
        "      candidate_ID_to_ranks[ID][1] = index\n",
        "\n",
        "  candidate_IDs = [ID for ID in candidate_ID_to_ranks.keys()]\n",
        "\n",
        "  SciBERT_score_IDs = get_SciBERT_scores(candidate_IDs, test_context)\n",
        "\n",
        "  for index, [score, ID] in enumerate(SciBERT_score_IDs):\n",
        "    candidate_ID_to_ranks[ID][2] = index\n",
        "\n",
        "  candidate_ID_ranks = []\n",
        "\n",
        "  for key in candidate_ID_to_ranks.keys():\n",
        "    candidate_ID_ranks.append([combine_ranks(candidate_ID_to_ranks[key], test_point), key])\n",
        "\n",
        "  candidate_ID_ranks = sorted(candidate_ID_ranks)\n",
        "  return candidate_ID_ranks\n",
        "\n",
        "def format_year(year_string):\n",
        "  if not year_string or year_string == '':\n",
        "    return 0\n",
        "  return int(year_string)\n",
        "\n",
        "def rank_papers(candidate_ID_ranks):\n",
        "  global database\n",
        "  paper_scores = []\n",
        "\n",
        "  # Store\n",
        "  # 0. p_r: Lowest Observed Context Rank of the Paper\n",
        "  # 1. p_s: Total support for the paper\n",
        "  # 2. rec_p: Recency of the paper\n",
        "  # 3. store_index: Added such that no comparisons are made between two dictionaries\n",
        "  # 4. The paper node\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for [rank, ID] in candidate_ID_ranks:\n",
        "    mapped_papers = database[ID][1]\n",
        "\n",
        "    for [paper, support] in mapped_papers:\n",
        "      found = False\n",
        "      for index, scored_paper in enumerate(paper_scores):\n",
        "        if is_same_paper(scored_paper[4], paper):\n",
        "          found = True\n",
        "          paper_scores[index][0] = min(paper_scores[index][0], rank)\n",
        "          paper_scores[index][1] = paper_scores[index][1] - support\n",
        "          break\n",
        "      if not found:\n",
        "        paper_scores.append([rank, - support, - format_year(paper['year']), count, paper])\n",
        "        count += 1\n",
        "\n",
        "  paper_scores = sorted(paper_scores)\n",
        "  return [paper_score[4] for paper_score in paper_scores]"
      ],
      "metadata": {
        "id": "r7kgji9D2M57"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if run_unit_test:\n",
        "  test_index = 0\n",
        "  context_ranks = rank_candidate_contexts(test_set[test_index], BM25Okapi_fetched[test_index], BM25Plus_fetched[test_index])\n",
        "  ranked_papers = rank_papers(context_ranks)\n",
        "  print('Suggested Papers:')\n",
        "  print(ranked_papers[0 : min(3, len(ranked_papers))])\n",
        "  print('Ground Truth Citations:')\n",
        "  print(test_set[0][1])\n",
        "  print('Reciprocal Rank: ' + str(Reci_Rank(ranked_papers, [paper for [paper, support] in test_set[test_index][1]])))\n",
        "  print('Recall at 1: ' + str(Rec_at_K(ranked_papers, [paper for [paper, support] in test_set[test_index][1]], 1)))\n",
        "  print('Recall at 3: ' + str(Rec_at_K(ranked_papers, [paper for [paper, support] in test_set[test_index][1]], 3)))\n",
        "  print('Recall at 5: ' + str(Rec_at_K(ranked_papers, [paper for [paper, support] in test_set[test_index][1]], 5)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE7DLv-967pD",
        "outputId": "1a42b411-048d-4bab-919f-eb13a5a20a11"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggested Papers:\n",
            "[{'title': 'Efficient Estimation of Word Representations in Vector Space', 'authors': [{'first': 'Tomas', 'middle': [], 'last': 'Mikolov', 'suffix': ''}, {'first': 'Kai', 'middle': [], 'last': 'Chen', 'suffix': ''}, {'first': 'Greg', 'middle': [], 'last': 'Corrado', 'suffix': ''}, {'first': 'Jeffrey', 'middle': [], 'last': 'Dean', 'suffix': ''}], 'year': 2013, 'venue': '', 'link': '5959482'}, {'title': 'Toward mention detection robustness with recurrent neural networks', 'authors': [{'first': 'T', 'middle': ['H'], 'last': 'Nguyen', 'suffix': ''}, {'first': 'A', 'middle': [], 'last': 'Sil', 'suffix': ''}, {'first': 'G', 'middle': [], 'last': 'Dinu', 'suffix': ''}, {'first': 'R', 'middle': [], 'last': 'Florian', 'suffix': ''}], 'year': 2016, 'venue': '', 'link': '6228859'}, {'title': 'Distributed representations of words and phrases and their compositionality', 'authors': [{'first': 'T', 'middle': [], 'last': 'Mikolov', 'suffix': ''}, {'first': 'I', 'middle': [], 'last': 'Sutskever', 'suffix': ''}, {'first': 'K', 'middle': [], 'last': 'Chen', 'suffix': ''}, {'first': 'G', 'middle': ['S'], 'last': 'Corrado', 'suffix': ''}, {'first': 'J', 'middle': [], 'last': 'Dean', 'suffix': ''}], 'year': 2013, 'venue': 'Advances in Neural Information Processing Systems', 'link': '16447573'}]\n",
            "Ground Truth Citations:\n",
            "[[{'title': 'Efficient estimation of word representations in vector space', 'authors': [{'first': 'T', 'middle': [], 'last': 'Mikolov', 'suffix': ''}, {'first': 'K', 'middle': [], 'last': 'Chen', 'suffix': ''}, {'first': 'G', 'middle': [], 'last': 'Corrado', 'suffix': ''}, {'first': 'J', 'middle': [], 'last': 'Dean', 'suffix': ''}], 'year': 2013, 'venue': '', 'link': '5959482'}, 1]]\n",
            "Reciprocal Rank: 1.0\n",
            "Recall at 1: 1\n",
            "Recall at 3: 1\n",
            "Recall at 5: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics():\n",
        "  test_set, database, BM25Okapi_fetched, BM25Plus_fetched = load_files(domain)\n",
        "  reci_ranks = []\n",
        "  recalls = {1: [], 3: [], 5: [], 10: []}\n",
        "\n",
        "  for test_index in range(len(test_set)):\n",
        "    context_ranks = rank_candidate_contexts(test_set[test_index], BM25Okapi_fetched[test_index], BM25Plus_fetched[test_index])\n",
        "    ranked_papers = rank_papers(context_ranks)\n",
        "    reci_ranks.append(Reci_Rank(ranked_papers, [paper for [paper, support] in test_set[test_index][1]]))\n",
        "    for K in recalls.keys():\n",
        "      recalls[K].append(Rec_at_K(ranked_papers, [paper for [paper, support] in test_set[test_index][1]], K))\n",
        "\n",
        "  metrics = {'MRR': numpy.mean(reci_ranks)}\n",
        "  for K in recalls.keys():\n",
        "    metrics['rec_' + str(K)] = numpy.mean(recalls[K])\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "VMYH4dHRcdiH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Experiments\n",
        "\n",
        "for domain in domains:\n",
        "  print('Domain: ' + str(domain) + '\\n')\n",
        "  test_set, database, BM25Okapi_fetched, BM25Plus_fetched = load_files(domain)\n",
        "\n",
        "  mode = 0\n",
        "  for consider_rankings in indices_possibilities:\n",
        "    indices = consider_rankings\n",
        "    print('Regular mode with considered rankings: ' + str(indices))\n",
        "    print(get_metrics())\n",
        "  print()\n",
        "\n",
        "  mode = 1\n",
        "  for threshold in [45, 47.5, 50, 52.5, 55]:\n",
        "    switch_threshold = threshold\n",
        "    print('Hybrid mode with threshold: ' + str(switch_threshold))\n",
        "    print(get_metrics())\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFfv5nxoefk7",
        "outputId": "e70bcf09-aab3-4854-b998-456375b65292"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Domain: ner\n",
            "\n",
            "Regular mode with considered rankings: [2]\n",
            "{'MRR': 0.2624626371891884, 'rec_1': 0.188, 'rec_3': 0.268, 'rec_5': 0.342, 'rec_10': 0.428}\n",
            "Regular mode with considered rankings: [0, 2]\n",
            "{'MRR': 0.3127211553217219, 'rec_1': 0.228, 'rec_3': 0.334, 'rec_5': 0.404, 'rec_10': 0.506}\n",
            "Regular mode with considered rankings: [1, 2]\n",
            "{'MRR': 0.30772668490841415, 'rec_1': 0.22, 'rec_3': 0.338, 'rec_5': 0.4, 'rec_10': 0.496}\n",
            "Regular mode with considered rankings: [0, 1, 2]\n",
            "{'MRR': 0.31502140618088964, 'rec_1': 0.222, 'rec_3': 0.344, 'rec_5': 0.418, 'rec_10': 0.51}\n",
            "Regular mode with considered rankings: [0]\n",
            "{'MRR': 0.3455846275576505, 'rec_1': 0.26, 'rec_3': 0.38, 'rec_5': 0.43, 'rec_10': 0.512}\n",
            "Regular mode with considered rankings: [1]\n",
            "{'MRR': 0.34735650741711965, 'rec_1': 0.262, 'rec_3': 0.386, 'rec_5': 0.436, 'rec_10': 0.51}\n",
            "Regular mode with considered rankings: [0, 1]\n",
            "{'MRR': 0.35013264412075396, 'rec_1': 0.264, 'rec_3': 0.386, 'rec_5': 0.438, 'rec_10': 0.514}\n",
            "\n",
            "Hybrid mode with threshold: 45\n",
            "{'MRR': 0.3479304894712309, 'rec_1': 0.262, 'rec_3': 0.388, 'rec_5': 0.434, 'rec_10': 0.51}\n",
            "Hybrid mode with threshold: 47.5\n",
            "{'MRR': 0.34937643541717683, 'rec_1': 0.264, 'rec_3': 0.388, 'rec_5': 0.434, 'rec_10': 0.51}\n",
            "Hybrid mode with threshold: 50\n",
            "{'MRR': 0.3512235532116631, 'rec_1': 0.266, 'rec_3': 0.39, 'rec_5': 0.436, 'rec_10': 0.512}\n",
            "Hybrid mode with threshold: 52.5\n",
            "{'MRR': 0.3515568865449964, 'rec_1': 0.266, 'rec_3': 0.39, 'rec_5': 0.438, 'rec_10': 0.514}\n",
            "Hybrid mode with threshold: 55\n",
            "{'MRR': 0.3515568865449964, 'rec_1': 0.266, 'rec_3': 0.39, 'rec_5': 0.438, 'rec_10': 0.514}\n",
            "\n",
            "\n",
            "Domain: summ\n",
            "\n",
            "Regular mode with considered rankings: [2]\n",
            "{'MRR': 0.3155559312979442, 'rec_1': 0.234, 'rec_3': 0.346, 'rec_5': 0.392, 'rec_10': 0.496}\n",
            "Regular mode with considered rankings: [0, 2]\n",
            "{'MRR': 0.34795416052595135, 'rec_1': 0.266, 'rec_3': 0.374, 'rec_5': 0.414, 'rec_10': 0.52}\n",
            "Regular mode with considered rankings: [1, 2]\n",
            "{'MRR': 0.3525156074586399, 'rec_1': 0.274, 'rec_3': 0.37, 'rec_5': 0.408, 'rec_10': 0.526}\n",
            "Regular mode with considered rankings: [0, 1, 2]\n",
            "{'MRR': 0.35822669094927756, 'rec_1': 0.27, 'rec_3': 0.392, 'rec_5': 0.438, 'rec_10': 0.53}\n",
            "Regular mode with considered rankings: [0]\n",
            "{'MRR': 0.37052290207606586, 'rec_1': 0.282, 'rec_3': 0.41, 'rec_5': 0.458, 'rec_10': 0.53}\n",
            "Regular mode with considered rankings: [1]\n",
            "{'MRR': 0.37324862184965546, 'rec_1': 0.284, 'rec_3': 0.41, 'rec_5': 0.46, 'rec_10': 0.54}\n",
            "Regular mode with considered rankings: [0, 1]\n",
            "{'MRR': 0.3757097557210405, 'rec_1': 0.288, 'rec_3': 0.414, 'rec_5': 0.458, 'rec_10': 0.542}\n",
            "\n",
            "Hybrid mode with threshold: 45\n",
            "{'MRR': 0.3742091375852231, 'rec_1': 0.286, 'rec_3': 0.412, 'rec_5': 0.456, 'rec_10': 0.542}\n",
            "Hybrid mode with threshold: 47.5\n",
            "{'MRR': 0.3768758042518898, 'rec_1': 0.29, 'rec_3': 0.414, 'rec_5': 0.458, 'rec_10': 0.542}\n",
            "Hybrid mode with threshold: 50\n",
            "{'MRR': 0.37676714412117085, 'rec_1': 0.29, 'rec_3': 0.414, 'rec_5': 0.458, 'rec_10': 0.542}\n",
            "Hybrid mode with threshold: 52.5\n",
            "{'MRR': 0.37676714412117085, 'rec_1': 0.29, 'rec_3': 0.414, 'rec_5': 0.458, 'rec_10': 0.542}\n",
            "Hybrid mode with threshold: 55\n",
            "{'MRR': 0.37676714412117085, 'rec_1': 0.29, 'rec_3': 0.414, 'rec_5': 0.458, 'rec_10': 0.542}\n",
            "\n",
            "\n",
            "Domain: mt\n",
            "\n",
            "Regular mode with considered rankings: [2]\n",
            "{'MRR': 0.3858919315487368, 'rec_1': 0.288, 'rec_3': 0.43, 'rec_5': 0.488, 'rec_10': 0.56}\n",
            "Regular mode with considered rankings: [0, 2]\n",
            "{'MRR': 0.42961613575899626, 'rec_1': 0.342, 'rec_3': 0.458, 'rec_5': 0.514, 'rec_10': 0.614}\n",
            "Regular mode with considered rankings: [1, 2]\n",
            "{'MRR': 0.44116253670578276, 'rec_1': 0.352, 'rec_3': 0.472, 'rec_5': 0.542, 'rec_10': 0.63}\n",
            "Regular mode with considered rankings: [0, 1, 2]\n",
            "{'MRR': 0.4430503168166951, 'rec_1': 0.356, 'rec_3': 0.474, 'rec_5': 0.54, 'rec_10': 0.636}\n",
            "Regular mode with considered rankings: [0]\n",
            "{'MRR': 0.43568641683915893, 'rec_1': 0.332, 'rec_3': 0.506, 'rec_5': 0.546, 'rec_10': 0.62}\n",
            "Regular mode with considered rankings: [1]\n",
            "{'MRR': 0.4407174193341151, 'rec_1': 0.338, 'rec_3': 0.5, 'rec_5': 0.558, 'rec_10': 0.636}\n",
            "Regular mode with considered rankings: [0, 1]\n",
            "{'MRR': 0.44379162948417356, 'rec_1': 0.342, 'rec_3': 0.514, 'rec_5': 0.556, 'rec_10': 0.626}\n",
            "\n",
            "Hybrid mode with threshold: 45\n",
            "{'MRR': 0.4429422776023952, 'rec_1': 0.34, 'rec_3': 0.514, 'rec_5': 0.556, 'rec_10': 0.626}\n",
            "Hybrid mode with threshold: 47.5\n",
            "{'MRR': 0.4429422776023952, 'rec_1': 0.34, 'rec_3': 0.514, 'rec_5': 0.556, 'rec_10': 0.626}\n",
            "Hybrid mode with threshold: 50\n",
            "{'MRR': 0.4442184680785856, 'rec_1': 0.342, 'rec_3': 0.514, 'rec_5': 0.556, 'rec_10': 0.628}\n",
            "Hybrid mode with threshold: 52.5\n",
            "{'MRR': 0.44448513474525225, 'rec_1': 0.342, 'rec_3': 0.516, 'rec_5': 0.556, 'rec_10': 0.628}\n",
            "Hybrid mode with threshold: 55\n",
            "{'MRR': 0.44456132522144276, 'rec_1': 0.342, 'rec_3': 0.516, 'rec_5': 0.556, 'rec_10': 0.628}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# That's it"
      ],
      "metadata": {
        "id": "QiUkDE0Y2zWG"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}